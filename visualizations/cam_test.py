# -*- coding: utf-8 -*-
"""cam_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ZApbSk6yIQ1tIn_nfv4vs4qEzjL8Jla
"""

!pip3 install gputil

# import the necessary libraries

import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler
import torch.utils.data as data
from torch.autograd import Variable
import torch.nn.functional as F
import torch.nn as nn
import torch.optim as optim
import time
import os
import math
import cv2
import glob
from GPUtil import showUtilization as gpu_usage
import matplotlib.pyplot as plt

# now we set a standard random seed so that we can reproduce results
seed = 42
np.random.seed(seed)
torch.manual_seed(seed)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.enabled = True

from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive', force_remount=False)

# count the number of training/test/validation samples automatically
def count_percentage(train_ratio, validation_ratio, test_ratio):
    count_positive = sum([len(files) for (r, d, files) in
                         os.walk('/content/drive/My Drive/IDP/test/pos/'
                         )])
    
    print('Total postive labeled images: ' + str(count_positive))
    
    count_negative = sum([len(files) for (r, d, files) in
                         os.walk('/content/drive/My Drive/IDP/test/neg/'
                         )])
    print('Total negative labeled images: ' + str(count_negative))
    
    total_files = count_positive + count_negative
    
    if count_positive > count_negative:
        difference = count_positive - count_negative
        average = total_files / 2
        relative_percentage = difference / average * 100
        print('The Positive Dataset is relatively bigger by: ' \
            + '{0:.2f}'.format(relative_percentage) + '%')
    else:
        difference = count_negative - count_positive
        average = total_files / 2
        relative_percentage = difference / average * 100
        print('The Negative Dataset is relatively bigger by: ' \
            + '{0:.2f}'.format(relative_percentage) + '%')
    
    training_samples = math.floor(total_files * train_ratio)
    testing_samples = math.floor(total_files * test_ratio)
    validation_samples = math.floor(total_files * validation_ratio)
    
    return training_samples, validation_samples, testing_samples

n_training_samples, n_val_samples, n_test_samples = count_percentage(0.5, 0.3, 0.2)
print (n_training_samples, n_test_samples, n_val_samples)

# populate the dateset and pass it to the train-test-validation loader
# load the image dataset
transform = transforms.Compose([transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
dataset = torchvision.datasets.ImageFolder("/content/drive/My Drive/IDP/test/", transform = transform)

# now we split the available training data into training, test and cross validation

# Training data
train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))

# Validation
val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype = np.int64))

# Test
test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))

class Net(nn.Module):
    def __init__(self, num_inputs, action_space):
        super(Net, self).__init__()
        # convolutional layer
        self.conv1 = nn.Conv2d(num_inputs, 16, 5)
        # max pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, 5)
        self.dropout = nn.Dropout(0.2)
        num_outputs = action_space
        self.fc1 = nn.Linear(32*53*53, 256)
        self.fc2 = nn.Linear(256, 84)
        self.fc3 = nn.Linear(84, num_outputs)
        self.softmax = nn.Softmax(dim=1)

        
    def forward(self, x):
        # add sequence of convolutional and max pooling layers
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.dropout(x)
        x = x.view(-1, 32 * 53 * 53)
        x = F.relu(self.fc1(x))
        x = self.dropout(F.relu(self.fc2(x)))
        x = self.softmax(self.fc3(x))
        return x

# DataLaoder
# Takes in a dataset and a sampler for loading
# num_workers deals with system memory and threads

def get_train_loader(batch_size):
    """
    Args:
        batch_size = number of images to be taken in a single batch
    """
    train_loader = data.DataLoader(dataset, batch_size=batch_size,
                                  sampler=train_sampler, num_workers=1)
    
    return train_loader
  
# Test and Validation loaders have constant batch size, so we can define them directly

test_loader = data.DataLoader(dataset, batch_size=4, sampler=test_sampler, num_workers=1)
val_loader = data.DataLoader(dataset, batch_size=32, sampler=val_sampler, num_workers=1)

# define the loss and opitmizer functions
# we use the CrossEntropyLoss and ADAM as Optimizer

def createLossAndOptimizer(net, learning_rate):
    # Loss function
    loss = nn.CrossEntropyLoss()
    
    # Optimizer
    optimizer = optim.Adam(net.parameters(), lr=learning_rate)
    
    return(loss, optimizer)

# Define a function to train the CNN 

def trainNet(net, batch_size, number_of_epochs, learning_rate):
    # Print all the hyperparameters of the training iteration
    print("Hyperparameters: ")
    print("Batch size = ", batch_size)
    print("epochs = ", number_of_epochs)
    print("Learning Rate = ", learning_rate)
    
    # Get Training Data
    train_loader = get_train_loader(batch_size)
    number_of_batches = len(train_loader)
    
    # Create our loss and optimizer functions
    loss, optimizer = createLossAndOptimizer(net, learning_rate)
    
    # Keep track of time
    training_start_time = time.time()
    
    print("GPU Usage before starting the first epoch")
    gpu_usage()
    print(number_of_epochs)
    # Loop for number_of_epochs
    for epoch in range(number_of_epochs):
        #print("inside for loop")
        train_loss = 0.0
        total_val_loss = 0
        accuracy = 0
        print_every = number_of_batches // 10
        start_time = time.time()
        total_train_loss = 0.0
        #print("GPU Usage in epoch: ", epoch)
        gpu_usage()
        
        for i, data in enumerate(train_loader, 0):
            # Get inputs
            #print("Get inputs")
            inputs, labels = data
            inputs = inputs.to(device)
            labels = labels.to(device)
            # Wraps them in a Variable object
            inputs, labels = Variable(inputs), Variable(labels)
            
            # Set the parameter gradients to zero
            # And make the forward pass, calculate gradient, do backprop
            optimizer.zero_grad()
            outputs = net(inputs)
            loss_size = loss(outputs, labels)
            del(inputs)
            del(labels)
            loss_size.backward()
            optimizer.step()
            #gpu_usage()
            # Print statistics
            train_loss += loss_size.data
            #print("Calculates train loss: ", train_loss)
            total_train_loss += loss_size.data
            #print("Calculates total train loss: ", total_train_loss)
            
            # Print every 10th batch of an epoch
            if (i + 1) % (print_every + 1) == 0:
                #print("Epoch {}, {:d}% \t Train loss: {:.2f} took: {:.2f}s".format(
                epoch+1, int(100* (i+1)/number_of_batches),
                train_loss / print_every,
                #time.time() - start_time()
                #print("GPU Usage:")
                gpu_usage()
                # Reset running loss and time
                train_loss = 0.0
                start_time = time.time()
                
        # At the end of the epoch, do a pass on the validation set
        
        for inputs, labels in val_loader:
            # Wrap tensors in variables
            inputs, labels = Variable(inputs), Variable(labels)
            inputs = inputs.to(device)
            labels = labels.to(device)
            # Forward pass
            val_outputs = net(inputs)
            val_loss_size = loss(val_outputs, labels)
            total_val_loss += val_loss_size.data
            
        print("validation loss = {:.2f}".format(total_val_loss / len(val_loader)))
    
    torch.save(net.state_dict(), '/content/drive/My Drive/IDP/test_model.pt')
    
    print("Training finished. Took: {:.2f}s".format(time.time() - training_start_time))

# Create the network and run it

cnn = Net(3,2)
cnn = cnn.to(device)
print(cnn)
train_on_gpu = torch.cuda.is_available() #will return true if gpu available
print("CUDA support: " + str(train_on_gpu))
# move tensors to GPU if CUDA is available
#print("Initial GPU Usage")
#gpu_usage() 
trainNet(cnn, batch_size=32, number_of_epochs=5, learning_rate=0.0001)

if not os.path.exists('/content/drive/My Drive/IDP/result/'):
    os.mkdir('/content/drive/My Drive/IDP/result/')

classes = ('positive', 'negative')
test_loader = data.DataLoader(dataset, batch_size=4, sampler=test_sampler, num_workers=1)

is_cuda = torch.cuda.is_available()
device = torch.device("cuda" if is_cuda else "cpu")


net = Net(3,2)
net = torch.load('/content/drive/My Drive/IDP/test_model.pt', map_location={'cuda:0': 'cpu', 'cuda:1' : 'cpu'})
#net.eval()
#net = net.to(device)
#finalconv_name = 'conv'

fig = plt.figure()
plt.figure(figsize=(20,20))
for idx, filt  in enumerate(net['conv1.weight']):
    #print(filt[0, :, :])
    plt.subplot(4,4, idx + 1)
    plt.imshow(filt[0, :, :], cmap="gray")
    plt.axis('off')
    
    
fig.show()
plt.savefig('/content/drive/My Drive/IDP/result/conv_1.jpg')

fig = plt.figure()
plt.figure(figsize=(20,20))
for idx, filt  in enumerate(net['conv2.weight']):
    #print(filt[0, :, :])
    plt.subplot(4,4, idx + 1)
    plt.imshow(filt[0, :, :], cmap="gray")
    plt.axis('off')
    
plt.savefig('/content/drive/My Drive/IDP/result/conv_2.jpg')   
fig.show()

from PIL import Image
img_test = Image.open("/content/drive/My Drive/IDP/test/neg/0.png")

img_test

net_1 = Net(3,2)
#net_1.load_state_dict(net)

preprocess = transforms.Compose([
    transforms.Grayscale(),
    transforms.ToTensor()
])

tensor_test = preprocess(img_test)


test_var = Variable(tensor_test.unsqueeze(0), volatile=True)
print(type(test_var))
test_var.cpu()
hx = Variable(torch.zeros(1, 512), volatile=True)
cx = Variable(torch.zeros(1, 512), volatile=True)
output = net_1((test_var, (hx, cx)))